{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODvAnkgbIEmSRJjAWOjx2C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poojatambe/Yolov7-Missing-Object-detection/blob/main/Missing_object_detection_v7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3L4P6Mnd4GfV",
        "outputId": "d03415a1-f6cb-4926-8f34-005a7d783e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-65.3.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 53.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: setuptools, pip\n",
            "\u001b[33m  WARNING: The scripts pip, pip3 and pip3.7 are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\n",
            "Successfully installed pip-22.2.2 setuptools-65.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (4.1.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.12.2->onnx) (1.15.0)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.12.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.12.1-cp37-cp37m-manylinux_2_27_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (1.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (21.3)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (1.21.6)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (2.0.7)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->onnxruntime) (3.0.9)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->onnxruntime) (1.15.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->onnxruntime) (1.2.1)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.12.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m/bin/bash: 4.21.3: No such file or directory\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.12.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (111.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from onnxruntime-gpu) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime-gpu) (2.0.7)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.7/dist-packages (from onnxruntime-gpu) (15.0.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime-gpu) (3.17.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from onnxruntime-gpu) (1.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from onnxruntime-gpu) (21.3)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.7/dist-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->onnxruntime-gpu) (3.0.9)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->onnxruntime-gpu) (1.15.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->onnxruntime-gpu) (1.2.1)\n",
            "Installing collected packages: onnxruntime-gpu\n",
            "Successfully installed onnxruntime-gpu-1.12.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script cmark is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script onnxsim is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade setuptools pip --user\n",
        "!pip install onnx \n",
        "!pip install onnxruntime\n",
        "#!pip install --ignore-installed PyYAML\n",
        "#!pip install Pillow\n",
        "\n",
        "!pip install protobuf<4.21.3\n",
        "!pip install onnxruntime-gpu\n",
        "!pip install onnx>=1.9.0\n",
        "!pip install onnx-simplifier>=0.3.6 --user"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clone yolov7 git repo\n",
        "! git clone https://github.com/WongKinYiu/yolov7.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6kggNUxEXi-",
        "outputId": "7ad66be7-d697-4bcf-c459-8f788bccc44d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 924, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 924 (delta 24), reused 73 (delta 21), pack-reused 845\u001b[K\n",
            "Receiving objects: 100% (924/924), 68.25 MiB | 27.78 MiB/s, done.\n",
            "Resolving deltas: 100% (449/449), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!# Download trained weights\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KNufqcODq6a",
        "outputId": "a9c96807-8b55-45f6-8184-6b450aa018b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-05 13:27:31--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220905%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220905T132731Z&X-Amz-Expires=300&X-Amz-Signature=d71a4abd2610671b56f5946a78e96622d920acda117553c4d1b01a901c2b9f1f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-09-05 13:27:31--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220905%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220905T132731Z&X-Amz-Expires=300&X-Amz-Signature=d71a4abd2610671b56f5946a78e96622d920acda117553c4d1b01a901c2b9f1f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75587165 (72M) [application/octet-stream]\n",
            "Saving to: ‘yolov7.pt’\n",
            "\n",
            "yolov7.pt           100%[===================>]  72.08M  32.5MB/s    in 2.2s    \n",
            "\n",
            "2022-09-05 13:27:34 (32.5 MB/s) - ‘yolov7.pt’ saved [75587165/75587165]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# export model to onnx\n",
        "%cd /content/yolov7/\n",
        "!python export.py --weights ./yolov7.pt \\\n",
        "        --grid --end2end --simplify \\\n",
        "        --topk-all 100 --iou-thres 0.65 --conf-thres 0.35 \\\n",
        "        --img-size 640 640 --max-wh 640 # For onnxruntime, you need to specify this value as an integer, when it is 0 it means agnostic NMS, \n",
        "                     # otherwise it is non-agnostic NMS"
      ],
      "metadata": {
        "id": "LZySW6YjEAUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a0c66e-ddbf-4b72-b6a1-1df90b20757e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "Import onnx_graphsurgeon failure: No module named 'onnx_graphsurgeon'\n",
            "Namespace(batch_size=1, conf_thres=0.35, device='cpu', dynamic=False, dynamic_batch=False, end2end=True, fp16=False, grid=True, img_size=[640, 640], include_nms=False, int8=False, iou_thres=0.65, max_wh=640, simplify=True, topk_all=100, weights='./yolov7.pt')\n",
            "YOLOR 🚀 v0.1-107-g44d8ab4 torch 1.12.1+cu113 CPU\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "Model Summary: 306 layers, 36905341 parameters, 36905341 gradients\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\n",
            "Starting TorchScript export with torch 1.12.1+cu113...\n",
            "/content/yolov7/models/yolo.py:52: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
            "TorchScript export success, saved as ./yolov7.torchscript.pt\n",
            "CoreML export failure: No module named 'coremltools'\n",
            "\n",
            "Starting TorchScript-Lite export with torch 1.12.1+cu113...\n",
            "TorchScript-Lite export success, saved as ./yolov7.torchscript.ptl\n",
            "\n",
            "Starting ONNX export with onnx 1.12.0...\n",
            "onnxruntime\n",
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:477.)\n",
            "  return self._grad\n",
            "/content/yolov7/models/experimental.py:99: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  batches = torch.randint(0, batch, (num_det,)).sort()[0].to(device)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/onnx/symbolic_opset9.py:4194: UserWarning: Exporting aten::index operator of advanced indexing in opset 12 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
            "  + \"If indices include negative values, the exported graph will produce incorrect results.\"\n",
            "\n",
            "Starting to simplify ONNX...\n",
            "ONNX export success, saved as ./yolov7.onnx\n",
            "\n",
            "Export complete (61.16s). Visualize with https://github.com/lutzroeder/netron.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from collections import OrderedDict,namedtuple\n",
        "\n",
        "cuda= False\n",
        "w = \"/content/yolov7/yolov7.onnx\"\n",
        "\n",
        "providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if cuda else ['CPUExecutionProvider']\n",
        "session = ort.InferenceSession(w, providers=providers)\n",
        "\n",
        "\n",
        "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n",
        "    # Resize and pad image while meeting stride-multiple constraints\n",
        "    shape = im.shape[:2]  # current shape [height, width]\n",
        "    if isinstance(new_shape, int):\n",
        "        new_shape = (new_shape, new_shape)\n",
        "\n",
        "    # Scale ratio (new / old)\n",
        "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
        "    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
        "        r = min(r, 1.0)\n",
        "\n",
        "    # Compute padding\n",
        "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
        "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
        "\n",
        "    if auto:  # minimum rectangle\n",
        "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
        "\n",
        "    dw /= 2  # divide padding into 2 sides\n",
        "    dh /= 2\n",
        "\n",
        "    if shape[::-1] != new_unpad:  # resize\n",
        "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
        "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
        "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
        "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
        "    return im, r, (dw, dh)\n",
        "\n",
        "names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', \n",
        "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', \n",
        "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', \n",
        "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', \n",
        "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', \n",
        "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', \n",
        "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', \n",
        "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', \n",
        "         'hair drier', 'toothbrush']\n",
        "colors = {name:[random.randint(0, 255) for _ in range(3)] for i,name in enumerate(names)}\n",
        "\n",
        "outname = [i.name for i in session.get_outputs()]\n",
        "print('outname',outname)\n",
        "\n",
        "inname = [i.name for i in session.get_inputs()]\n",
        "print('inname',inname)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfXp5RN7Enyd",
        "outputId": "35d117ef-b558-4922-eeef-47ceefee7dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['images']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# video to detect missing object\n",
        "cap = cv2.VideoCapture('/content/test19.mp4')\n",
        "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "fps =int(cap.get(cv2.CAP_PROP_FPS))\n",
        "cap_width,cap_height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# save output in the video format\n",
        "output= cv2.VideoWriter('missing_v7.avi', codec,fps, (cap_width, cap_height), True)\n",
        "\n",
        "# objects to monitor\n",
        "obj=['car','truck']\n",
        "\n",
        "frame=0\n",
        "while True:\n",
        "  #reading video frame by frame and checking for its null conditio\n",
        "  _, img= cap.read()\n",
        "\n",
        "  #count frame\n",
        "  frame +=1\n",
        "\n",
        "  #object count for current frame set to zero\n",
        "  curr_count=0\n",
        "  if img is None:\n",
        "    print('Completed')\n",
        "    break\n",
        "\n",
        "  else:\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    image = img.copy()\n",
        "    image, ratio, dwdh = letterbox(image, auto=False)\n",
        "    image = image.transpose((2, 0, 1))\n",
        "    image = np.expand_dims(image, 0)\n",
        "    image = np.ascontiguousarray(image)\n",
        "    im = image.astype(np.float32)\n",
        "    im /= 255\n",
        "    inp = {inname[0]:im}\n",
        "\n",
        "    # count objects in first frame and increment ref_count\n",
        "    if frame==1:\n",
        "      ref_count=0\n",
        "      outputs = session.run(outname, inp)[0]\n",
        "      for i,(batch_id,x0,y0,x1,y1,cls_id,score) in enumerate(outputs):\n",
        "        cls_id = int(cls_id)\n",
        "        name = names[cls_id]\n",
        "        score = round(float(score),)\n",
        "        if name in obj and (score > 0.5): # check if detected object is matching with obj specified and confidence score of detection is more than 0.5\n",
        "          ref_count+=1\n",
        "    else:\n",
        "      # count objects in remaining frames and increment count of current frame\n",
        "      outputs = session.run(outname, inp)[0]\n",
        "      for i,(batch_id,x0,y0,x1,y1,cls_id,score) in enumerate(outputs):\n",
        "        cls_id = int(cls_id)\n",
        "        name = names[cls_id]\n",
        "        score = round(float(score),)\n",
        "        if name in obj and (score > 0.5): # check if detected object is matching with obj specified and confidence score of detection is more than 0.5\n",
        "          curr_count+=1\n",
        "\n",
        "    # compare current object count with reference object count\n",
        "    if curr_count < ref_count:\n",
        "      cv2.putText(img,\" object is missing.\",(10,30),cv2.FONT_HERSHEY_SIMPLEX,1,[0, 0, 255],thickness=2)\n",
        "    output.write(img)\n",
        "output.release()\n",
        "cap.release()\n",
        "\n",
        " \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctab6xisGTPf",
        "outputId": "e3796760-e067-4ab5-9164-04a309403255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "1 2\n",
            "car\n",
            "car\n",
            "1 2\n",
            "car\n",
            "car\n",
            "1 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "mouse\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "mouse\n",
            "2 2\n",
            "car\n",
            "car\n",
            "mouse\n",
            "2 2\n",
            "car\n",
            "car\n",
            "mouse\n",
            "2 2\n",
            "car\n",
            "car\n",
            "mouse\n",
            "2 2\n",
            "car\n",
            "car\n",
            "mouse\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "mouse\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "0 2\n",
            "car\n",
            "1 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "mouse\n",
            "2 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "mouse\n",
            "car\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "1 2\n",
            "car\n",
            "car\n",
            "car\n",
            "1 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "1 2\n",
            "car\n",
            "car\n",
            "1 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "car\n",
            "2 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "0 2\n",
            "mouse\n",
            "car\n",
            "0 2\n",
            "mouse\n",
            "car\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "motorcycle\n",
            "1 2\n",
            "car\n",
            "motorcycle\n",
            "1 2\n",
            "car\n",
            "motorcycle\n",
            "1 2\n",
            "car\n",
            "1 2\n",
            "car\n",
            "1 2\n",
            "mouse\n",
            "0 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "1 2\n",
            "car\n",
            "1 2\n",
            "car\n",
            "1 2\n",
            "car\n",
            "parking meter\n",
            "1 2\n",
            "car\n",
            "1 2\n",
            "car\n",
            "1 2\n",
            "car\n",
            "person\n",
            "1 2\n",
            "car\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "0 2\n",
            "person\n",
            "car\n",
            "0 2\n",
            "car\n",
            "0 2\n",
            "car\n",
            "0 2\n",
            "car\n",
            "1 2\n",
            "car\n",
            "1 2\n",
            "car\n",
            "1 2\n",
            "car\n",
            "1 2\n",
            "car\n",
            "motorcycle\n",
            "0 2\n",
            "car\n",
            "mouse\n",
            "0 2\n",
            "mouse\n",
            "car\n",
            "0 2\n",
            "mouse\n",
            "0 2\n",
            "mouse\n",
            "car\n",
            "0 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "0 2\n",
            "car\n",
            "1 2\n",
            "mouse\n",
            "0 2\n",
            "mouse\n",
            "car\n",
            "1 2\n",
            "car\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "mouse\n",
            "car\n",
            "car\n",
            "1 2\n",
            "mouse\n",
            "car\n",
            "car\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "car\n",
            "2 2\n",
            "mouse\n",
            "car\n",
            "car\n",
            "2 2\n",
            "mouse\n",
            "car\n",
            "1 2\n",
            "mouse\n",
            "car\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "1 2\n",
            "car\n",
            "1 2\n",
            "car\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "mouse\n",
            "car\n",
            "0 2\n",
            "mouse\n",
            "0 2\n",
            "mouse\n",
            "0 2\n",
            "mouse\n",
            "car\n",
            "0 2\n",
            "mouse\n",
            "car\n",
            "0 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "car\n",
            "mouse\n",
            "1 2\n",
            "Completed\n"
          ]
        }
      ]
    }
  ]
}